{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f9859c0-0d34-470f-970e-9a0c3dd94e27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Data Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a50bc4-8d6a-4f32-b595-f520a777d562",
   "metadata": {},
   "source": [
    "## Loading and exploring the climate and CO2 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fad69b-615a-41e3-a444-ad811fe877e8",
   "metadata": {},
   "source": [
    "First we have a look of all the data sets that we were provided. We have data from Kaggle, our world in data and Nasa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92e5f209-1186-4961-a670-23776af24a8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2404f57e-459d-4638-ac30-4223ae9653e1",
   "metadata": {},
   "source": [
    "### Load Temperature data Kaggle\n",
    "Let's load the Kaggle climate data first. The data was retrieved from [Kaggle](https://www.kaggle.com/datasets/sevgisarac/temperature-change/?select=FAOSTAT_data_1-10-2022.csv).\n",
    "The reference Period for the temperature here is also 1951â€“1980. Here, by country, we see the average temperature deviation per month per year. Pretty straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34805196-2b6d-4105-a89f-31c003d1fe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\juliu\\AppData\\Local\\Temp\\ipykernel_27464\\896144834.py:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  tmp_df = pd.read_csv(filepath_or_buffer =\"D:\\Data\\Dropbox\\LifeAfter\\Datascientest\\Climate\\Data\\Kaggle_data\\FAOSTAT_data_1-10-2022.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 229925 entries, 0 to 229924\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Domain Code       229925 non-null  object \n",
      " 1   Domain            229925 non-null  object \n",
      " 2   Area Code (FAO)   229925 non-null  int64  \n",
      " 3   Area              229925 non-null  object \n",
      " 4   Element Code      229925 non-null  int64  \n",
      " 5   Element           229925 non-null  object \n",
      " 6   Months Code       229925 non-null  int64  \n",
      " 7   Months            229925 non-null  object \n",
      " 8   Year Code         229925 non-null  int64  \n",
      " 9   Year              229925 non-null  int64  \n",
      " 10  Unit              229925 non-null  object \n",
      " 11  Value             222012 non-null  float64\n",
      " 12  Flag              229925 non-null  object \n",
      " 13  Flag Description  229925 non-null  object \n",
      "dtypes: float64(1), int64(5), object(8)\n",
      "memory usage: 24.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Fc', 'NV'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df = pd.read_csv(filepath_or_buffer =\"D:\\Data\\Dropbox\\LifeAfter\\Datascientest\\Climate\\Data\\Kaggle_data\\FAOSTAT_data_1-10-2022.csv\")\n",
    "display(tmp_df.info())\n",
    "tmp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a89a9-1484-4ba4-b693-4053a2274e22",
   "metadata": {},
   "source": [
    "Okay, we can see domain code is a useless column (says only temperature change), same as \"Domain Code\", Element and Element Code. \n",
    "We miss approximately ~8000 Temperature deviation values. Careful a couple of country area codes might be mismatched according to the kaggle website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c90b22d-7670-4bb6-9c74-b5bfb44f8caa",
   "metadata": {},
   "source": [
    "#### Kaggle Data Set 2\n",
    "This data set only contains information pertaining to the area code. For the analysis, we can safely ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb896c38-6f68-478e-84a5-ebb33211af16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 321 entries, 0 to 320\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Country Code  321 non-null    int64  \n",
      " 1   Country       321 non-null    object \n",
      " 2   M49 Code      304 non-null    float64\n",
      " 3   ISO2 Code     245 non-null    object \n",
      " 4   ISO3 Code     257 non-null    object \n",
      " 5   Start Year    39 non-null     float64\n",
      " 6   End Year      9 non-null      float64\n",
      "dtypes: float64(3), int64(1), object(3)\n",
      "memory usage: 17.7+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\juliu\\AppData\\Local\\Temp\\ipykernel_27464\\2777278764.py:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  tmp_df1 = pd.read_csv(filepath_or_buffer =\"D:\\Data\\Dropbox\\LifeAfter\\Datascientest\\Climate\\Data\\Kaggle_data\\FAOSTAT_data_11-24-2020.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_df1 = pd.read_csv(filepath_or_buffer =\"D:\\Data\\Dropbox\\LifeAfter\\Datascientest\\Climate\\Data\\Kaggle_data\\FAOSTAT_data_11-24-2020.csv\")\n",
    "display(tmp_df1.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534725b-c0d9-4ffd-9f2b-3dd2b1a43fca",
   "metadata": {},
   "source": [
    "#### Kaggle Data Set 3\n",
    "This seems to be just a pivoted version of csv file 1. Feel free to ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a81e2d-4007-4e77-9919-6564d95e7f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\juliu\\AppData\\Local\\Temp\\ipykernel_27464\\468125335.py:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  tmp_df3 = pd.read_csv(filepath_or_buffer =\"D:\\Data\\Dropbox\\LifeAfter\\Datascientest\\Climate\\Data\\Kaggle_data\\Environment_Temperature_change_E_All_Data_NOFLAG.csv\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9656 entries, 0 to 9655\n",
      "Data columns (total 66 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Area Code     9656 non-null   int64  \n",
      " 1   Area          9656 non-null   object \n",
      " 2   Months Code   9656 non-null   int64  \n",
      " 3   Months        9656 non-null   object \n",
      " 4   Element Code  9656 non-null   int64  \n",
      " 5   Element       9656 non-null   object \n",
      " 6   Unit          9656 non-null   object \n",
      " 7   Y1961         8287 non-null   float64\n",
      " 8   Y1962         8322 non-null   float64\n",
      " 9   Y1963         8294 non-null   float64\n",
      " 10  Y1964         8252 non-null   float64\n",
      " 11  Y1965         8281 non-null   float64\n",
      " 12  Y1966         8364 non-null   float64\n",
      " 13  Y1967         8347 non-null   float64\n",
      " 14  Y1968         8345 non-null   float64\n",
      " 15  Y1969         8326 non-null   float64\n",
      " 16  Y1970         8308 non-null   float64\n",
      " 17  Y1971         8303 non-null   float64\n",
      " 18  Y1972         8323 non-null   float64\n",
      " 19  Y1973         8394 non-null   float64\n",
      " 20  Y1974         8374 non-null   float64\n",
      " 21  Y1975         8280 non-null   float64\n",
      " 22  Y1976         8209 non-null   float64\n",
      " 23  Y1977         8257 non-null   float64\n",
      " 24  Y1978         8327 non-null   float64\n",
      " 25  Y1979         8290 non-null   float64\n",
      " 26  Y1980         8283 non-null   float64\n",
      " 27  Y1981         8276 non-null   float64\n",
      " 28  Y1982         8237 non-null   float64\n",
      " 29  Y1983         8205 non-null   float64\n",
      " 30  Y1984         8259 non-null   float64\n",
      " 31  Y1985         8216 non-null   float64\n",
      " 32  Y1986         8268 non-null   float64\n",
      " 33  Y1987         8284 non-null   float64\n",
      " 34  Y1988         8273 non-null   float64\n",
      " 35  Y1989         8257 non-null   float64\n",
      " 36  Y1990         8239 non-null   float64\n",
      " 37  Y1991         8158 non-null   float64\n",
      " 38  Y1992         8354 non-null   float64\n",
      " 39  Y1993         8315 non-null   float64\n",
      " 40  Y1994         8373 non-null   float64\n",
      " 41  Y1995         8409 non-null   float64\n",
      " 42  Y1996         8439 non-null   float64\n",
      " 43  Y1997         8309 non-null   float64\n",
      " 44  Y1998         8370 non-null   float64\n",
      " 45  Y1999         8324 non-null   float64\n",
      " 46  Y2000         8342 non-null   float64\n",
      " 47  Y2001         8241 non-null   float64\n",
      " 48  Y2002         8312 non-null   float64\n",
      " 49  Y2003         8390 non-null   float64\n",
      " 50  Y2004         8415 non-null   float64\n",
      " 51  Y2005         8424 non-null   float64\n",
      " 52  Y2006         8503 non-null   float64\n",
      " 53  Y2007         8534 non-null   float64\n",
      " 54  Y2008         8475 non-null   float64\n",
      " 55  Y2009         8419 non-null   float64\n",
      " 56  Y2010         8435 non-null   float64\n",
      " 57  Y2011         8437 non-null   float64\n",
      " 58  Y2012         8350 non-null   float64\n",
      " 59  Y2013         8427 non-null   float64\n",
      " 60  Y2014         8377 non-null   float64\n",
      " 61  Y2015         8361 non-null   float64\n",
      " 62  Y2016         8348 non-null   float64\n",
      " 63  Y2017         8366 non-null   float64\n",
      " 64  Y2018         8349 non-null   float64\n",
      " 65  Y2019         8365 non-null   float64\n",
      "dtypes: float64(59), int64(3), object(4)\n",
      "memory usage: 4.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_df3 = pd.read_csv(filepath_or_buffer =\"D:\\Data\\Dropbox\\LifeAfter\\Datascientest\\Climate\\Data\\Kaggle_data\\Environment_Temperature_change_E_All_Data_NOFLAG.csv\",\n",
    "                     encoding = 'latin-1')\n",
    "display(tmp_df3.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcec87f-0493-4df9-82b5-66b25f76e9c7",
   "metadata": {},
   "source": [
    "### Load CO2 data\n",
    "The CO2 data is retrieved from the [GitHub page](https://github.com/owid/co2-data?tab=readme-ov-file) \"of our World in data\". A lot of interesting variables, but also a ton of missing data. Will be interesting to check out. Data is also only available on a yearly instead of a monthly basis. Also Something we should have a look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3f1ab3-f152-4297-8a79-71ee20ddb896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\juliu\\AppData\\Local\\Temp\\ipykernel_27464\\539647427.py:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  CO2_df = pd.read_csv(filepath_or_buffer =\"D:\\Data\\Dropbox\\LifeAfter\\Datascientest\\Climate\\Data\\CO2_data\\owid-co2-data.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47415 entries, 0 to 47414\n",
      "Data columns (total 79 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   country                                    47415 non-null  object \n",
      " 1   year                                       47415 non-null  int64  \n",
      " 2   iso_code                                   39548 non-null  object \n",
      " 3   population                                 39414 non-null  float64\n",
      " 4   gdp                                        14495 non-null  float64\n",
      " 5   cement_co2                                 23764 non-null  float64\n",
      " 6   cement_co2_per_capita                      22017 non-null  float64\n",
      " 7   co2                                        30308 non-null  float64\n",
      " 8   co2_growth_abs                             28157 non-null  float64\n",
      " 9   co2_growth_prct                            25136 non-null  float64\n",
      " 10  co2_including_luc                          23320 non-null  float64\n",
      " 11  co2_including_luc_growth_abs               23030 non-null  float64\n",
      " 12  co2_including_luc_growth_prct              23313 non-null  float64\n",
      " 13  co2_including_luc_per_capita               23320 non-null  float64\n",
      " 14  co2_including_luc_per_gdp                  15608 non-null  float64\n",
      " 15  co2_including_luc_per_unit_energy          9608 non-null   float64\n",
      " 16  co2_per_capita                             26600 non-null  float64\n",
      " 17  co2_per_gdp                                16290 non-null  float64\n",
      " 18  co2_per_unit_energy                        10241 non-null  float64\n",
      " 19  coal_co2                                   25075 non-null  float64\n",
      " 20  coal_co2_per_capita                        24389 non-null  float64\n",
      " 21  consumption_co2                            4718 non-null   float64\n",
      " 22  consumption_co2_per_capita                 4365 non-null   float64\n",
      " 23  consumption_co2_per_gdp                    3899 non-null   float64\n",
      " 24  cumulative_cement_co2                      23681 non-null  float64\n",
      " 25  cumulative_co2                             28495 non-null  float64\n",
      " 26  cumulative_co2_including_luc               23320 non-null  float64\n",
      " 27  cumulative_coal_co2                        24992 non-null  float64\n",
      " 28  cumulative_flaring_co2                     24909 non-null  float64\n",
      " 29  cumulative_gas_co2                         25000 non-null  float64\n",
      " 30  cumulative_luc_co2                         37022 non-null  float64\n",
      " 31  cumulative_oil_co2                         25028 non-null  float64\n",
      " 32  cumulative_other_co2                       2593 non-null   float64\n",
      " 33  energy_per_capita                          10019 non-null  float64\n",
      " 34  energy_per_gdp                             7120 non-null   float64\n",
      " 35  flaring_co2                                24992 non-null  float64\n",
      " 36  flaring_co2_per_capita                     24261 non-null  float64\n",
      " 37  gas_co2                                    25083 non-null  float64\n",
      " 38  gas_co2_per_capita                         24352 non-null  float64\n",
      " 39  ghg_excluding_lucf_per_capita              6354 non-null   float64\n",
      " 40  ghg_per_capita                             6354 non-null   float64\n",
      " 41  land_use_change_co2                        37022 non-null  float64\n",
      " 42  land_use_change_co2_per_capita             36313 non-null  float64\n",
      " 43  methane                                    6355 non-null   float64\n",
      " 44  methane_per_capita                         6355 non-null   float64\n",
      " 45  nitrous_oxide                              6355 non-null   float64\n",
      " 46  nitrous_oxide_per_capita                   6355 non-null   float64\n",
      " 47  oil_co2                                    25111 non-null  float64\n",
      " 48  oil_co2_per_capita                         24380 non-null  float64\n",
      " 49  other_co2_per_capita                       2447 non-null   float64\n",
      " 50  other_industry_co2                         2593 non-null   float64\n",
      " 51  primary_energy_consumption                 10061 non-null  float64\n",
      " 52  share_global_cement_co2                    20208 non-null  float64\n",
      " 53  share_global_co2                           28495 non-null  float64\n",
      " 54  share_global_co2_including_luc             23320 non-null  float64\n",
      " 55  share_global_coal_co2                      24992 non-null  float64\n",
      " 56  share_global_cumulative_cement_co2         20208 non-null  float64\n",
      " 57  share_global_cumulative_co2                28495 non-null  float64\n",
      " 58  share_global_cumulative_co2_including_luc  23320 non-null  float64\n",
      " 59  share_global_cumulative_coal_co2           24992 non-null  float64\n",
      " 60  share_global_cumulative_flaring_co2        16129 non-null  float64\n",
      " 61  share_global_cumulative_gas_co2            22156 non-null  float64\n",
      " 62  share_global_cumulative_luc_co2            37022 non-null  float64\n",
      " 63  share_global_cumulative_oil_co2            23513 non-null  float64\n",
      " 64  share_global_cumulative_other_co2          2593 non-null   float64\n",
      " 65  share_global_flaring_co2                   16129 non-null  float64\n",
      " 66  share_global_gas_co2                       22156 non-null  float64\n",
      " 67  share_global_luc_co2                       37022 non-null  float64\n",
      " 68  share_global_oil_co2                       23513 non-null  float64\n",
      " 69  share_global_other_co2                     2593 non-null   float64\n",
      " 70  share_of_temperature_change_from_ghg       41280 non-null  float64\n",
      " 71  temperature_change_from_ch4                37840 non-null  float64\n",
      " 72  temperature_change_from_co2                41280 non-null  float64\n",
      " 73  temperature_change_from_ghg                41280 non-null  float64\n",
      " 74  temperature_change_from_n2o                37840 non-null  float64\n",
      " 75  total_ghg                                  6354 non-null   float64\n",
      " 76  total_ghg_excluding_lucf                   6354 non-null   float64\n",
      " 77  trade_co2                                  4398 non-null   float64\n",
      " 78  trade_co2_share                            4397 non-null   float64\n",
      "dtypes: float64(76), int64(1), object(2)\n",
      "memory usage: 28.6+ MB\n"
     ]
    }
   ],
   "source": [
    "CO2_df = pd.read_csv(filepath_or_buffer =\"D:\\Data\\Dropbox\\LifeAfter\\Datascientest\\Climate\\Data\\CO2_data\\owid-co2-data.csv\")\n",
    "CO2_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba4434-55fb-4fa4-851c-f59279b12f37",
   "metadata": {},
   "source": [
    "### Load the NASA data files\n",
    "Lastly, we load the temperature anomaly (deviation - reference period 1951-1980) which was retrieved from [NASA](https://data.giss.nasa.gov/gistemp/). First, we load the global mean data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f3ab618-9bf0-48ce-8779-667a1c1afd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Land-Ocean: Global Means</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "      <th>J-D</th>\n",
       "      <th>D-N</th>\n",
       "      <th>DJF</th>\n",
       "      <th>MAM</th>\n",
       "      <th>JJA</th>\n",
       "      <td>SON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <th>-.18</th>\n",
       "      <th>-.24</th>\n",
       "      <th>-.09</th>\n",
       "      <th>-.16</th>\n",
       "      <th>-.10</th>\n",
       "      <th>-.21</th>\n",
       "      <th>-.18</th>\n",
       "      <th>-.10</th>\n",
       "      <th>-.14</th>\n",
       "      <th>-.23</th>\n",
       "      <th>-.22</th>\n",
       "      <th>-.17</th>\n",
       "      <th>-.17</th>\n",
       "      <th>***</th>\n",
       "      <th>***</th>\n",
       "      <th>-.11</th>\n",
       "      <th>-.16</th>\n",
       "      <td>-.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <th>-.20</th>\n",
       "      <th>-.14</th>\n",
       "      <th>.03</th>\n",
       "      <th>.05</th>\n",
       "      <th>.06</th>\n",
       "      <th>-.19</th>\n",
       "      <th>.00</th>\n",
       "      <th>-.04</th>\n",
       "      <th>-.15</th>\n",
       "      <th>-.22</th>\n",
       "      <th>-.19</th>\n",
       "      <th>-.07</th>\n",
       "      <th>-.09</th>\n",
       "      <th>-.10</th>\n",
       "      <th>-.17</th>\n",
       "      <th>.05</th>\n",
       "      <th>-.08</th>\n",
       "      <td>-.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <th>.16</th>\n",
       "      <th>.14</th>\n",
       "      <th>.05</th>\n",
       "      <th>-.17</th>\n",
       "      <th>-.15</th>\n",
       "      <th>-.24</th>\n",
       "      <th>-.17</th>\n",
       "      <th>-.08</th>\n",
       "      <th>-.14</th>\n",
       "      <th>-.24</th>\n",
       "      <th>-.16</th>\n",
       "      <th>-.36</th>\n",
       "      <th>-.11</th>\n",
       "      <th>-.09</th>\n",
       "      <th>.08</th>\n",
       "      <th>-.09</th>\n",
       "      <th>-.16</th>\n",
       "      <td>-.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <th>-.29</th>\n",
       "      <th>-.37</th>\n",
       "      <th>-.12</th>\n",
       "      <th>-.18</th>\n",
       "      <th>-.18</th>\n",
       "      <th>-.08</th>\n",
       "      <th>-.07</th>\n",
       "      <th>-.14</th>\n",
       "      <th>-.21</th>\n",
       "      <th>-.11</th>\n",
       "      <th>-.23</th>\n",
       "      <th>-.11</th>\n",
       "      <th>-.17</th>\n",
       "      <th>-.20</th>\n",
       "      <th>-.34</th>\n",
       "      <th>-.16</th>\n",
       "      <th>-.10</th>\n",
       "      <td>-.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          Land-Ocean: Global Means\n",
       "Year Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec  J-D  D-N  DJF  MAM  JJA                       SON\n",
       "1880 -.18 -.24 -.09 -.16 -.10 -.21 -.18 -.10 -.14 -.23 -.22 -.17 -.17 ***  ***  -.11 -.16                     -.20\n",
       "1881 -.20 -.14 .03  .05  .06  -.19 .00  -.04 -.15 -.22 -.19 -.07 -.09 -.10 -.17 .05  -.08                     -.19\n",
       "1882 .16  .14  .05  -.17 -.15 -.24 -.17 -.08 -.14 -.24 -.16 -.36 -.11 -.09 .08  -.09 -.16                     -.18\n",
       "1883 -.29 -.37 -.12 -.18 -.18 -.08 -.07 -.14 -.21 -.11 -.23 -.11 -.17 -.20 -.34 -.16 -.10                     -.19"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Global_mean_temp_df = pd.read_csv(filepath_or_buffer = r\"D:\\Data\\Dropbox\\LifeAfter\\Datascientest\\Climate\\Data\\NASA\\GLB.Ts+dSST.csv\")\n",
    "Global_mean_temp_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339df8a-2366-4c57-bc5b-1da702ba12ea",
   "metadata": {},
   "source": [
    "From What I can gather J-D is the yearly mean from January to December, whereas D-N is the yearly mean from December to November. DJF is short for a mean of December, January, and February, and so forth. The only actual missing values that we see here come from rounding, when the temp is not in the data set.\n",
    "\n",
    "#### NASA Northern Hemisphere mean data\n",
    "Same Thing as the global data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fecc881-3fff-4a19-a4ec-3fd29b58e08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Land-Ocean: Northern Hemispheric Means</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "      <th>J-D</th>\n",
       "      <th>D-N</th>\n",
       "      <th>DJF</th>\n",
       "      <th>MAM</th>\n",
       "      <th>JJA</th>\n",
       "      <td>SON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <th>-.35</th>\n",
       "      <th>-.51</th>\n",
       "      <th>-.22</th>\n",
       "      <th>-.30</th>\n",
       "      <th>-.06</th>\n",
       "      <th>-.15</th>\n",
       "      <th>-.18</th>\n",
       "      <th>-.26</th>\n",
       "      <th>-.23</th>\n",
       "      <th>-.32</th>\n",
       "      <th>-.42</th>\n",
       "      <th>-.40</th>\n",
       "      <th>-.28</th>\n",
       "      <th>***</th>\n",
       "      <th>***</th>\n",
       "      <th>-.19</th>\n",
       "      <th>-.20</th>\n",
       "      <td>-.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <th>-.31</th>\n",
       "      <th>-.23</th>\n",
       "      <th>-.04</th>\n",
       "      <th>.00</th>\n",
       "      <th>.03</th>\n",
       "      <th>-.34</th>\n",
       "      <th>.07</th>\n",
       "      <th>-.05</th>\n",
       "      <th>-.27</th>\n",
       "      <th>-.44</th>\n",
       "      <th>-.37</th>\n",
       "      <th>-.24</th>\n",
       "      <th>-.18</th>\n",
       "      <th>-.20</th>\n",
       "      <th>-.31</th>\n",
       "      <th>.00</th>\n",
       "      <th>-.11</th>\n",
       "      <td>-.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <th>.26</th>\n",
       "      <th>.21</th>\n",
       "      <th>.02</th>\n",
       "      <th>-.32</th>\n",
       "      <th>-.25</th>\n",
       "      <th>-.31</th>\n",
       "      <th>-.29</th>\n",
       "      <th>-.15</th>\n",
       "      <th>-.25</th>\n",
       "      <th>-.52</th>\n",
       "      <th>-.33</th>\n",
       "      <th>-.67</th>\n",
       "      <th>-.22</th>\n",
       "      <th>-.18</th>\n",
       "      <th>.08</th>\n",
       "      <th>-.18</th>\n",
       "      <th>-.25</th>\n",
       "      <td>-.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <th>-.57</th>\n",
       "      <th>-.66</th>\n",
       "      <th>-.15</th>\n",
       "      <th>-.29</th>\n",
       "      <th>-.25</th>\n",
       "      <th>-.13</th>\n",
       "      <th>-.04</th>\n",
       "      <th>-.22</th>\n",
       "      <th>-.33</th>\n",
       "      <th>-.16</th>\n",
       "      <th>-.42</th>\n",
       "      <th>-.15</th>\n",
       "      <th>-.28</th>\n",
       "      <th>-.32</th>\n",
       "      <th>-.64</th>\n",
       "      <th>-.23</th>\n",
       "      <th>-.13</th>\n",
       "      <td>-.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          Land-Ocean: Northern Hemispheric Means\n",
       "Year Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec  J-D  D-N  DJF  MAM  JJA                                     SON\n",
       "1880 -.35 -.51 -.22 -.30 -.06 -.15 -.18 -.26 -.23 -.32 -.42 -.40 -.28 ***  ***  -.19 -.20                                   -.32\n",
       "1881 -.31 -.23 -.04 .00  .03  -.34 .07  -.05 -.27 -.44 -.37 -.24 -.18 -.20 -.31 .00  -.11                                   -.36\n",
       "1882 .26  .21  .02  -.32 -.25 -.31 -.29 -.15 -.25 -.52 -.33 -.67 -.22 -.18 .08  -.18 -.25                                   -.37\n",
       "1883 -.57 -.66 -.15 -.29 -.25 -.13 -.04 -.22 -.33 -.16 -.42 -.15 -.28 -.32 -.64 -.23 -.13                                   -.30"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Northern_mean_temp_df = pd.read_csv(filepath_or_buffer = r\"D:\\Data\\Dropbox\\LifeAfter\\Datascientest\\Climate\\Data\\NASA\\NH.Ts+dSST.csv\")\n",
    "Northern_mean_temp_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf89eae-ca4f-41d5-9273-1a36dbfa8196",
   "metadata": {},
   "source": [
    "#### Southern Hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "338b6ee7-2ebf-4c38-85a8-668e12eb0d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Land-Ocean: Southern Hemispheric Means</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "      <th>J-D</th>\n",
       "      <th>D-N</th>\n",
       "      <th>DJF</th>\n",
       "      <th>MAM</th>\n",
       "      <th>JJA</th>\n",
       "      <td>SON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <th>-.01</th>\n",
       "      <th>.03</th>\n",
       "      <th>.05</th>\n",
       "      <th>-.02</th>\n",
       "      <th>-.13</th>\n",
       "      <th>-.25</th>\n",
       "      <th>-.18</th>\n",
       "      <th>.06</th>\n",
       "      <th>-.05</th>\n",
       "      <th>-.15</th>\n",
       "      <th>-.01</th>\n",
       "      <th>.05</th>\n",
       "      <th>-.05</th>\n",
       "      <th>***</th>\n",
       "      <th>***</th>\n",
       "      <th>-.04</th>\n",
       "      <th>-.12</th>\n",
       "      <td>-.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <th>-.09</th>\n",
       "      <th>-.07</th>\n",
       "      <th>.09</th>\n",
       "      <th>.09</th>\n",
       "      <th>.08</th>\n",
       "      <th>-.06</th>\n",
       "      <th>-.08</th>\n",
       "      <th>-.03</th>\n",
       "      <th>-.04</th>\n",
       "      <th>-.01</th>\n",
       "      <th>-.01</th>\n",
       "      <th>.09</th>\n",
       "      <th>.00</th>\n",
       "      <th>-.01</th>\n",
       "      <th>-.04</th>\n",
       "      <th>.09</th>\n",
       "      <th>-.06</th>\n",
       "      <td>-.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <th>.06</th>\n",
       "      <th>.07</th>\n",
       "      <th>.07</th>\n",
       "      <th>-.02</th>\n",
       "      <th>-.05</th>\n",
       "      <th>-.16</th>\n",
       "      <th>-.05</th>\n",
       "      <th>.00</th>\n",
       "      <th>-.04</th>\n",
       "      <th>.03</th>\n",
       "      <th>-.02</th>\n",
       "      <th>-.08</th>\n",
       "      <th>-.01</th>\n",
       "      <th>.00</th>\n",
       "      <th>.07</th>\n",
       "      <th>.00</th>\n",
       "      <th>-.07</th>\n",
       "      <td>-.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <th>-.03</th>\n",
       "      <th>-.09</th>\n",
       "      <th>-.09</th>\n",
       "      <th>-.07</th>\n",
       "      <th>-.10</th>\n",
       "      <th>-.03</th>\n",
       "      <th>-.09</th>\n",
       "      <th>-.06</th>\n",
       "      <th>-.10</th>\n",
       "      <th>-.06</th>\n",
       "      <th>-.05</th>\n",
       "      <th>-.06</th>\n",
       "      <th>-.07</th>\n",
       "      <th>-.07</th>\n",
       "      <th>-.06</th>\n",
       "      <th>-.09</th>\n",
       "      <th>-.06</th>\n",
       "      <td>-.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          Land-Ocean: Southern Hemispheric Means\n",
       "Year Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec  J-D  D-N  DJF  MAM  JJA                                     SON\n",
       "1880 -.01 .03  .05  -.02 -.13 -.25 -.18 .06  -.05 -.15 -.01 .05  -.05 ***  ***  -.04 -.12                                   -.07\n",
       "1881 -.09 -.07 .09  .09  .08  -.06 -.08 -.03 -.04 -.01 -.01 .09  .00  -.01 -.04 .09  -.06                                   -.02\n",
       "1882 .06  .07  .07  -.02 -.05 -.16 -.05 .00  -.04 .03  -.02 -.08 -.01 .00  .07  .00  -.07                                   -.01\n",
       "1883 -.03 -.09 -.09 -.07 -.10 -.03 -.09 -.06 -.10 -.06 -.05 -.06 -.07 -.07 -.06 -.09 -.06                                   -.07"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Southern_mean_temp_df = pd.read_csv(filepath_or_buffer = r\"D:\\Data\\Dropbox\\LifeAfter\\Datascientest\\Climate\\Data\\NASA\\SH.Ts+dSST.csv\")\n",
    "Southern_mean_temp_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cdf9cf-87f4-4085-a0f7-67c665d09a6b",
   "metadata": {},
   "source": [
    "#### Zone Annual Meansabs\n",
    "Annual mean Land-Ocean Temperature Index in 0.01 degrees Celsius selected zonal means. Columns probably correspond to Zones, but I am not sure how to interpret though. FYI no troubles with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c04623c-f65c-414b-a7aa-681e82204645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Glob</th>\n",
       "      <th>NHem</th>\n",
       "      <th>SHem</th>\n",
       "      <th>24N-90N</th>\n",
       "      <th>24S-24N</th>\n",
       "      <th>90S-24S</th>\n",
       "      <th>64N-90N</th>\n",
       "      <th>44N-64N</th>\n",
       "      <th>24N-44N</th>\n",
       "      <th>EQU-24N</th>\n",
       "      <th>24S-EQU</th>\n",
       "      <th>44S-24S</th>\n",
       "      <th>64S-44S</th>\n",
       "      <th>90S-64S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1880</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1881</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1882</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1883</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1884</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Glob  NHem  SHem  24N-90N  24S-24N  90S-24S  64N-90N  44N-64N  \\\n",
       "0  1880 -0.17 -0.28 -0.05    -0.37    -0.13    -0.02    -0.82    -0.47   \n",
       "1  1881 -0.09 -0.18  0.00    -0.35     0.10    -0.07    -0.94    -0.46   \n",
       "2  1882 -0.11 -0.22 -0.01    -0.32    -0.05     0.01    -1.43    -0.29   \n",
       "3  1883 -0.17 -0.28 -0.07    -0.34    -0.17    -0.02    -0.19    -0.57   \n",
       "4  1884 -0.29 -0.43 -0.15    -0.61    -0.15    -0.14    -1.32    -0.65   \n",
       "\n",
       "   24N-44N  EQU-24N  24S-EQU  44S-24S  64S-44S  90S-64S  \n",
       "0    -0.28    -0.15    -0.11    -0.05     0.05     0.67  \n",
       "1    -0.20     0.10     0.10    -0.06    -0.07     0.60  \n",
       "2    -0.14    -0.05    -0.05     0.01     0.04     0.63  \n",
       "3    -0.24    -0.18    -0.16    -0.04     0.07     0.50  \n",
       "4    -0.46    -0.13    -0.17    -0.20    -0.02     0.65  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zone_mean_temp_df = pd.read_csv(filepath_or_buffer = r\"D:\\Data\\Dropbox\\LifeAfter\\Datascientest\\Climate\\Data\\NASA\\ZonAnn.Ts+dSST.csv\")\n",
    "Zone_mean_temp_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
